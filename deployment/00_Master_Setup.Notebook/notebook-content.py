# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "061b5888-c63f-4658-b28e-fffb5af3ca67",
# META       "default_lakehouse_name": "lh_f1",
# META       "default_lakehouse_workspace_id": "399cf811-13f0-4d3d-80bb-5f12b960d7a3",
# META       "known_lakehouses": [
# META         {
# META           "id": "061b5888-c63f-4658-b28e-fffb5af3ca67"
# META         }
# META       ]
# META     }
# META   }
# META }

# CELL ********************

# 1. INSTALACI√ìN AUTOM√ÅTICA (La l√≠nea m√°gica que faltaba)
# Esto asegura que la librer√≠a exista antes de intentar importarla
%pip install semantic-link-labs

# 2. IMPORTACI√ìN Y L√ìGICA
import sempy_labs as sl
import time

# --- CONFIGURACI√ìN AUTOM√ÅTICA ---
# Al dejarlo en None, se aplicar√° al workspace y lakehouse actuales del notebook
MODEL_NAME = "F1_Gold_Model"  # Aseg√∫rate de que este sea el nombre exacto

print(f"üîÑ Iniciando remapeo autom√°tico del modelo: {MODEL_NAME}")

try:
    # 1. Remapear la conexi√≥n (Cablear al Lakehouse actual)
    print("   üîå Buscando Lakehouse adjunto para reconectar...")
    sl.directlake.update_direct_lake_model_connection(
        dataset = MODEL_NAME,
        source_type = "Lakehouse",
        use_sql_endpoint = True
    )
    print("   ‚úÖ Conexi√≥n remapeada con √©xito.")

    # 2. Sincronizar el esquema (Leer las tablas nuevas)
    print("   üîÑ Sincronizando esquema...")
    sl.directlake.direct_lake_schema_sync(
        dataset = MODEL_NAME
    )
    print("   ‚úÖ Esquema sincronizado.")

    print("\nüöÄ ¬°LISTO! El modelo ya apunta a tus datos locales.")

except Exception as e:
    print(f"\n‚ùå Error: {e}")
    print("üí° PISTA: ¬øHas a√±adido un Lakehouse al panel izquierdo ('Lakehouses') de este notebook?")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
